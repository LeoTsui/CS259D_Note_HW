# A Multi-Model Approach to the Detection of Web-Based Attacks

<!-- TOC -->

- [Insight](#insight)
- [Goal](#goal)
- [Architecture](#architecture)
- [Web-related attack detection](#web-related-attack-detection)
- [Data model](#data-model)
- [Detection models](#detection-models)
    - [Attribute length](#attribute-length)
        - [User](#user)
        - [Attacker](#attacker)
        - [Learning](#learning)
        - [Detection](#detection)
    - [Attribute character distribution](#attribute-character-distribution)
        - [User](#user)
        - [Attacker](#attacker)
        - [Learning](#learning)
        - [Detection](#detection)
    - [Structural inference](#structural-inference)
        - [User](#user)
        - [Attacker](#attacker)
        - [Learning](#learning)
        - [Detection](#detection)
    - [Token finder](#token-finder)
        - [User](#user)
        - [Attacker](#attacker)
        - [Learning](#learning)
        - [Detection](#detection)
    - [Attribute presence or absence](#attribute-presence-or-absence)
        - [User](#user)
        - [Attacker](#attacker)
        - [Learning](#learning)
        - [Detection](#detection)
    - [Attribute order](#attribute-order)
        - [User](#user)
        - [Attacker](#attacker)
        - [Learning](#learning)
        - [Detection](#detection)
    - [Access frequency](#access-frequency)
        - [User](#user)
        - [Attacker](#attacker)
        - [Learning](#learning)
        - [Detection](#detection)
    - [Inter-request time delay](#inter-request-time-delay)
        - [User](#user)
        - [Attacker](#attacker)
        - [Learning](#learning)
        - [Detection](#detection)
    - [Invocation order](#invocation-order)
        - [User](#user)
        - [Attacker](#attacker)
        - [Learning](#learning)
        - [Detection](#detection)
- [Limitation](#limitation)
- [Reference](#reference)

<!-- /TOC -->

## Insight

* Web servers accessible by outside world
* Web apps developed with security as an afterthought
* Developing ad hoc signatures is a time-intensive and error-prone activity
* What's new
    1. A number of different models
        * Reduce vulnerability
    2. Target specific types of applications
        * More focused analysis

## Goal

* Animaly detextion system, detect web-based attacks
* Unsupervised, learning-based anomaly detection
* Deployed on host

## Architecture

* Input: Web server log files
  * Common Log Format (CLF)
* Analysis: build profiles for apps & active docs
    * Lower error rates than generic profiles
    * Use multiple models
        * Reduce vulnerability to mimicry attacks
* Output: Anomaly score for each web request

## Web-related attack detection

1. Relay on models of the intended behavior of user and application
2. Assume attack patterns is **different** from normal behavior
3. The **defference** can be expressed either quantitatively or qualitatively
4. Interprets deviations from this "normal" behavior as **evidence**


* Misuse-based detection
    * Example: Snort
        * 1037 out of 2464 signatures
    * Hard to keep up-to-date
        * Time-intensive, error-prone, requires significant security expertise
    * Challenge with apps developed in-house
    * Unable to detect un-modeled attacks
* Anomaly-based
    * Applicable to custom-developed web apps
    * Support detection of new attacks
* Classification of intrusion detection

## Data model

* An ordered set $U=\{u_1,u_2,...,u_m\}$ of URIs
    * Extract from successful GET requests
    * $200 \leq \text{return-code} < 300$
* Components of $u_i$
    * Path to desired resource: pathi
    * Optional path information: pinfoi
    * Optional query string: $q$
        * Following a "?" Character
        * Passing parameters to referenced resource
        * Attributes and values: $q = (a_1, v_1), (a_2, v_2), ..., (a_n, v_n)$
        * $A$, the set of all attributes, $a_i$ belongs to $A$
        * $v_i$ is a string
        * $S_q = \{a_1=v_1, a_2=v_2, ..., a_n=v_n\}$
* URIs without query strings not included in $U$
* $U_r$: subset of $U$ with resource path $r$
    * Partition $U$
    * Anomaly detection run independently on each $U_r$

## Detection models

* One model, one query
* Task: returns probability $p$ of normalcy
* Alerting on a single anomalous attribute is **necessarily  excessively cautious**
* Anomaly Score
* Has an associated weight $w$
    * Default $\text{value} = 1$, in this paper
* Training mode
    1. Create profiles for each server-side program  and each of its attributes
    2. Establish suitable thresholds
        * Store the highest anomaly score
        * Default thresholds: $10\%$ larger than the max anomaly score
* Detection mode

### Attribute length

* Length distribution mot follow a smooth curve
* Distribution has a large variance

#### User

* Fixed size tokens
    * Session identifiers
* Short input strings
    * Fields in an HTML form

#### Attacker

* Buffer overflow: shell code & padding
    * Several hundred bytes
* XSS

#### Learning

* Estimate mean Î¼ and variance $\sigma^2$ of lengths in training data

#### Detection

* Strings with length larger than mean
    * If $\text{length} < \text{mean}$, $p = 1$
    * Padding not effective
* **Chebyshev inequality is weak bound**
* **Useful to flag only significant outliers**

### Attribute character distribution

* Character distribution: sorted relative frequencies
    * Lost relative frequencies
    * Example: $\text{passwd} \Rightarrow 0.33, 0.17, 0.17, 0.17, 0.17, 0, ..., 0$
    * Fall smoothly for human-readable tokens
    * Fall quickly for malicious input

#### User

* Observations about attributes:
    * Regular structure
    * Mostly human readable
    * Almost always contain only printable characters
*  Frequencies of query parameters distribution
    * Not identical to a standard English text
    * Similar to others

#### Attacker

* Example:
    * Buffer overflow: needs to send binary data & padding
    * Directory traversal exploit: many dots in attribute value

#### Learning

* character distribution of each observed attribute is stored
* Average of all character distributions computed

#### Detection

* Variant of the $\text{Pearson}\ \chi^2\text{-test}$
    * goodness-of-fit
* Bins: $\{[0], [1, 3], [4, 6], [7, 11], [12, 15], [16, 255]\}$
* For each query attribute:
    * Compute character distribution
    * Observed values $O_i$ : Aggregate over bins
    * Expected values $E_i$ : Learned character distribution attribute length
* Compute: $\chi^2$
* Read corresponding probability

### Structural inference

#### User

* Parameter structure
    * Regular grammar describing all of its legitimate values

#### Attacker

* Detect exploits requiring different parameter structure
    * Examples: Buffer overflow, directory traversal, XSS
* Simple manifestations of an exploit
    * Unusually long parameters
    * Parameters containing repetitions of non-printable characters
* **Evasion**
    * Replace non-printable characters by groups of printable characters

#### Learning

* Seems to be "reasonable"
* Stop before lost much structural information
* Goal: Find a model(NFA) with highest likelihood given training examples
* Markov model/Non-deterministic finite automaton (NFA)
    * "Reasonable generalizaton"
    * $P_s(o)$: probability of emitting symbol $o$ at state $S$
    * $P(t)$: probability of transition $t$
    * Output: paths from Start state to Terminalstate
* Bayesian model induction:
    * $P(\text{model}\mid\text{training}\_\text{data}) = \frac{p(\text{training}\_\text{data}\mid\text{model})*p(\text{model})}{p(\text{training}\_\text{data})}$
    * $P(\text{training}\_\text{data})$ a scaling factor; ignored
    * $P(\text{training}\_\text{data}\mid\text{model})$ computed as last slide
    * $P(\text{model})$: preference towards smaller models
        * Total number of states: $N$
        * Total number of transitions at each state $S$: $T(S)$
        * Total number of emissions at each state $S$: $E(S)$
    * Start with a model exactly reflecting input data
    * Gradually merge states
    * Until posterior probability does not increase
    * Cost: $O((n*L)^3)$ with n training input strings, and L maximum length of each string
    * Up to $n*L$ states
    * $\frac{(n*L)(n*L-1)}{2}$ comparisons for each merging
    * Up to $n*(L-1)$ merges
* Optimizations
    * Viterbi path approximations
    * Path prefix compression
    * Cost: $O(n*L^2)$

#### Detection

* First option: Compute probability of query attribute
    * Issue: probabilities of all input words sum up to $1$
    * all words have small probabilities
* Output:
    * $p = 1$ if word is a valid output of Markov model
    * $p = 0$ otherwise

### Token finder

* Goal: determine whether values of an attribute are drawn from an enumerated set of tokens

#### User

* Web applications often require one out of a few possible values for certain query attributes
    * Example: flags, indices

#### Attacker

* Use these attributes to pass illegal values

#### Learning

* Enumerated or Random
* Growth in # of different argument instances compared to total # of argument instances
* Compute correlation between these numbers:
* $F(x) = x$
* $G(x)$, $G$ is like a "enumeration counter"
    * $G(x) = G(x-1)+1$ if $\text{x-th}$ value is new
    * $G(x) = G(x-1)-1$ if $\text{x-th}$ value was seen before
    * $G(x) = 0$ if $x = 0$
    * $Corr = \frac{Covar(F, G)}{\sqrt{Var(F)Var(G)}}$
    * If $Corr < 0$, then enumeration
    * If enumeration, then store all values for use in detection phase

#### Detection

* If enumeration: value expected to be among stored values
    * Output $p = 1$ or $p = 0$ correspondingly
    * If random: $p = 1$
    * Hash table lookup, efficiency

### Attribute presence or absence

#### User

* URIs typically produced not directly by user, but by scripts, forms, client-side programs
    * Regularity in number, name, order of parameters

#### Attacker

* Hand-crafted attacks typically break this regularity
    * Incomplete or malformed requests to probe/exploit web app
        * Missing argument
        * Mutually exclusive arguments appearing together

#### Learning

* Create a model of acceptable subsets of attributes
* Record each distinct set $S_q$
    * Each query $q$ during training
    * Hash table

#### Detection

* Lookup the attribute set in hash table
    * Return $p = 1$ or $p = 0$ correspondingly

### Attribute order

#### User

* same parameters in the same order
* sequential
* Sequential program logic preserves order even when some attributes left out

#### Attacker

* Arbitrary
* No influence on the execution of the program

#### Learning

* Attribute $a_s$ precedes $a_t$ if as and at appear together in parameter list of at least one query and $a_s$ comes before $a_t$  when theyappear together
* Directed graph
* $\text{number of vertices} = \text{number of attributes}$
* For each training query, add edges between nodes of ordered attribute pairs
* Find all strongly connected components (SCC) of the graph
* Remove edges between nodes in same SCC
* For each node, find all reachable nodes
* Add corresponding pairs to set of precedence orders
* Tarjan's algorithm, $O(v + e)$

#### Detection

* Find all order violations
    * Return $p = 0$ or $p = 1$ correspondingly

### Access frequency

* Frequency patterns of different server-side web applications
* Two types of frequencies:
    * Frequency of application being accessed from a certain client
        * Base on IP address
    * Total frequency of all accesses

#### User

* Eg 1. Authentication script
    * Very infrequently for each individual client
* Eg 2. Search script
    * High for particular client
    * Low for total

#### Attacker

* Suddenly increase access frequency
* Probing
* Guess parameter values
* Evasion: slow down

#### Learning

* divide training time to intervals of fixed time (e.g., 10 sec)
* Count accesses in each interval
* Find total and client-specific distributions

#### Detection

* Chebyshev probability for total, and for client
* Return average of the two probabilities

### Inter-request time delay

#### User

* Wide variance

#### Attacker

* Regular delay between each successive request
    * Surveillance
    * Scripted probe

#### Learning

* Find distribution of normal delays
    * Similar to character distribution model

#### Detection

* $\text{Pearson}\ \chi^2\text{-test}$

### Invocation order

* Order of invocation of web-based applications for each client
    * Infer session structure regularity
    * Similar to structural inference model
#### User

* Invocation order can be generated by a certain Markov model

#### Attacker

* Cannot be outputed by that model

#### Learning

* group queries based on source IP
    * Session: Queries within an interval of time
    * Build NFA for sessions

#### Detection

* $p = 1$ or $p = 0$ depending on session being an output of NFA

## Limitation

* Google
    * Nearly half of the number of false positives
        * Anomalous search strings that contain instances of non-printable characters
            * Probably requests issued by users with incompatible character sets
        * Extremely long strings
            * Such as URLs directly pasted into the search field

## Reference

* A multi-model approach to the detection of web-based attacks, 2005
* CS 259D Lecture 8
